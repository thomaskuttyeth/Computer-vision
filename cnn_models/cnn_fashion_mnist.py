# -*- coding: utf-8 -*-
"""cnn_fashion_mnist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13Oajhu5MxPicwxif2cGmnNlScJv0NhaL
"""

# !pip install keras-tuner

# importing libraries 
import tensorflow as tf 
from tensorflow import keras 
import numpy as np

print(tf.__version__)  # checking the tensorflow version

# loading the dataset 
fashion_mnist = keras.datasets.fashion_mnist

# train and test 
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

# normalizing 
train_images = train_images/255 
test_images = test_images/255

train_images[0].shape # checking the shape

# reshaping the images 
train_images = train_images.reshape(len(train_images), 28,28,1) 
test_images = test_images.reshape(len(test_images), 28,28, 1)

# creating function of tuner 
def build_model(hp):
    # hp is the hyperparameters 
    # creating the sequential model 
    model = keras.Sequential([

    # adding the first layer                          
    keras.layers.Conv2D(
        filters = hp.Int('conv_1_filter', min_value = 64, max_value = 128, step = 16), 
        kernel_size  = hp.Choice('conv_1_kernel', values  = [3,5]), 
        activation = 'relu',
        input_shape = (28,28,1) 
    ), 
    # adding the second layer 
    keras.layers.Conv2D(
        filters = hp.Int('conv_2_filter', min_value = 32, max_value = 64, step = 16), 
        kernel_size = hp.Choice('conv_2_kernel', values = [3,5]), 
        activation = 'relu'
    ), 
    # flattening the weights 
    keras.layers.Flatten(), 

    # adding the first dense layer 
    keras.layers.Dense(
        units = hp.Int('dense_1_units', min_value = 32, max_value = 128, step = 16), 
        activation = 'relu'
    ),

    # adding the final dense layer // 10 classes 
    keras.layers.Dense(10, activation = 'softmax')
    ])

    # model compiling 
    model.compile(
        optimizer = keras.optimizers.Adam(hp.Choice('learning_rate', values = [1e-2, 1e-3])), 
        loss = 'sparse_categorical_crossentropy', 
        metrics = ['accuracy']
    )
    return model

# !pip install keras-tuner --upgrade

from keras_tuner.engine.hyperparameters import HyperParameters 
from keras_tuner import RandomSearch

tuner_search = RandomSearch(
    build_model, 
    objective = 'val_accuracy', 
    max_trials = 5, 
    directory = 'output', 
    project_name = 'fashion-mnist'
)

tuner_search.search(train_images, 
    train_labels, 
    epochs = 2, 
    validation_split = 0.1)

model =  tuner_search.get_best_models(num_models = 1)[0]

model.summary()

model.fit(train_images, 
    train_labels, 
    epochs = 10 , 
    validation_split = 0.1, 
    initial_epoch = 3)

# A few random samples
use_samples = [2,3]
samples_to_predict = []

# Generate plots for samples
for sample in use_samples:
  # Generate a plot
  reshaped_image = test_images[sample].reshape((28, 28))
  plt.imshow(reshaped_image)
  plt.show()
  # Add sample to array for prediction
  
  samples_to_predict.append(test_images[sample])

# Convert into Numpy array
samples_to_predict = np.array(samples_to_predict)
samples_to_predict.shape

# Generate predictions for samples
predictions = model.predict(samples_to_predict)
print(predictions)

# Generate arg maxes for predictions
classes = np.argmax(predictions, axis = 1)
print(classes)

# actual test label 
test_labels[[3,2]] 
# so model correctly predicted the labels

